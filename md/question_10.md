# Билет №10
## Вопрос 1: Optimizers: Adam, NAdam.
> ### Chain rule
> $Chain\ rule$ -- производная сложной функции.
> 
> **Цепное правило (правило дифференцирования сложной функции)** позволяет вычислить производную композиции двух и более функций на основе индивидуальных производных. Если функция $f$ имеет производную в точке $x_{0}$, а функция $g$ имеет производную в точке $y_{0}=f(x_{0})$, то сложная функция $h(x)=g(f(x))$ также имеет производную в точке $x_{0}$.
> 
> В обозначениях Лейбница цепное правило для вычисления производной функции $y=y(x)$, где $x=x(t)$, принимает следующий вид:
> 
> $$\frac{dy}{dt} = \frac{dy}{dx} \cdot \frac{dt}{dt}$$
> ### Backpropagation
> $Backpropagation$ -- метод обновления весов сеток.
> [Источник того, что ниже -- википедия.](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B8)
> 
> **Метод обратного распространения ошибки** — метод вычисления градиента, который используется при обновлении весов многослойного перцептрона.
> Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы.
> #### Описание работы
> Алгоритм обратного распространения ошибки применяется для многослойного перцептрона. У сети есть множество входов $x_{1},...,x_{n}$, множество выходов $Outputs$ и множество внутренних узлов. Перенумеруем все узлы (включая входы и выходы) числами от $1$ до $N$ (сквозная нумерация, вне зависимости от топологии слоёв). Обозначим через  $w_{i,j}$ вес, стоящий на ребре, соединяющем $i$-й и $j$-й узлы, а через $o_i$ — выход $i$-го узла. Если нам известен обучающий пример (правильные ответы сети $t_k$, $k \in \mathrm{Outputs}$), то функция ошибки, полученная по методу наименьших квадратов, выглядит так:
>
>$$E(\{w_{i,j}\}) = \tfrac{1}{2} \!\! \sum_{k \in \mathrm{Outputs}} \!\!\! (t_k - o_k)^2 $$
>
> Как модифицировать веса? Мы будем реализовывать стохастический градиентный спуск, то есть будем подправлять веса после каждого обучающего примера и, таким образом, «двигаться» в многомерном пространстве весов. Чтобы «добраться» до минимума ошибки, нам нужно «двигаться» в сторону, противоположную градиенту, то есть, на основании каждой группы правильных ответов, добавлять к каждому весу $w_{i,j}$
>
> $$\Delta w_{i,j} = -\eta \frac {\partial E}{\partial w_{i,j}},$$
>
> где $0 < \eta < 1$ — множитель, задающий скорость «движения»
>
>Производная считается следующим образом. Пусть сначала $j \in \mathrm{Outputs}$, то есть интересующий нас вес входит в нейрон последнего уровня. Сначала отметим, что $w_{i,j}$ влияет на выход сети только как часть суммы  $S_j = \sum_{i} w_{i,j}x_{i}$, где сумма берётся по входам $j$-го узла. Поэтому
>
> $$\cfrac{\partial E}{\partial w_{i,j}} = \cfrac{\partial E}{\partial S_j}\, \cfrac{\partial S_j}{\partial w_{i,j}} = x_{i} \cfrac{\partial E}{\partial S_j} $$
>
> Аналогично, $S_j$ влияет на общую ошибку только в рамках выхода $j$-го узла $o_j$ (напоминаем, что это выход всей сети). Поэтому
>
>$$\cfrac{\partial E}{\partial S_j} = \cfrac{\partial E}{\partial o_j}\,\cfrac{\partial o_j}{\partial S_j} = \\ =\left (\cfrac{\partial}{\partial o_j}\,\cfrac{1}{2}\sum_{k \in \mathrm{Outputs}}(t_k - o_k)^2 \right ) \!\! \left (\cfrac{\partial \operatorname{f}(S)}{\partial S}\mid_{S=S_j} \right) = \\
\\ = \left ( \cfrac{1}{2}\, \cfrac{\partial}{\partial o_j}(t_j - o_j)^2 \right) (o_j(1 - o_j)) 2\alpha = - 2 \alpha o_j(1 - o_j)(t_j - o_j),$$
>
>где $f(S)$ — соответствующая сигмоида, в данном случае — экспоненциальная
>
>Если же $j$-й узел — не на последнем уровне, то у него есть выходы; обозначим их через $Children(j)$. В этом случае
>
>$$\cfrac{\partial E}{\partial S_j} = \sum_{k \in \mathrm{Children}(j)} \cfrac{\partial E}{\partial S_k}\, \cfrac{\partial S_k}{\partial S_j},$$
>и
>
>$$\cfrac{\partial S_k}{\partial S_j} = \cfrac{\partial S_k}{\partial o_j}\, \cfrac{\partial o_j}{\partial S_j} = w_{j,k} \cfrac{\partial o_j}{\partial S_j} = 2\alpha w_{j,k}o_j(1 - o_j).$$
>
>Но $\cfrac{\partial E}{\partial S_k}$ — это в точности аналогичная поправка, но вычисленная для узла следующего уровня. Будем обозначать её через $\delta _k$ — от $\Delta _k$ она отличается отсутствием множителя $(-\eta x_{i,j})$. Поскольку мы научились вычислять поправку для узлов последнего уровня и выражать поправку для узла более низкого уровня через поправки более высокого, можно уже писать алгоритм. Именно из-за этой особенности вычисления поправок алгоритм называется алгоритмом обратного распространения ошибки ($backpropagation$).
>
>Краткое резюме проделанной работы:
>* для узла последнего уровня:
>$$\delta _j = -2\alpha o_j(1 - o_j)(t_j - o_j)$$
>* для внутреннего узла сети:
>$$\delta _j = 2\alpha o_j(1 - o_j) \!\! \sum_{k \in \mathrm{Children}(j)} \!\! \delta _k w_{j,k}$$
>* для всех узлов:
>$$\Delta w_{i,j} = -\eta \delta _j o_{i},$$
>где $o_{i}$ это тот же $x_{i}$ в формуле для $\cfrac{\partial E}>{\partial w_{i,j}}$.
>
>[Источник того, что ниже - лекции.](https://docs.google.com/document/d/1HXz9Q7sp50WDAd3Fuk0eqzikXN90KmClK8fkG-2y0Iw/edit#)
>
>Итак, мы посчитали градиенты по каждому весу, но это градиенты функции ошибки, ее мы хотим минимизировать, так что веса будем двигать в сторону, противоположную градиенту. Замечание: могут встречаться оба варианта: подвигать по градиенту (если мы максимизируем какой-нибудь “gain”) или против (если минимизируем loss).
>Сам алгоритм:
>* инициализировать веса $w_{i, j}$ случайными величинами
>* $forward\ step$ - получаем $o_j$
>* $backward\ step$ - получаем $\delta_j$
>* обновляем веса
>
>Этот алгоритм лучше запускать несколько раз с разными начальными весами, потому что начиная с разных точек в пространстве весов и значения функции потерь мы можем скатываться в разные минимумы.

### Оптимизаторы

#### Adam

[Источник того, что ниже - хабр.](https://habr.com/post/318970/)

$Adam — ADAptive\ Moment\ estimation$

$Adam -$ это оптимизационный алгоритм.

> **Вспомним основы оптимизационных алгоритмов, основанных на накоплении:**
> Сама по себе идея методов с накоплением импульса до очевидности проста: «Если мы некоторое время движемся в определённом направлении, то, вероятно, нам следует туда двигаться некоторое время и в будущем». Для этого нужно уметь обращаться к недавней истории изменений каждого параметра. Можно хранить последние $n$ экземпляров $\Delta w$ и на каждом шаге по-честному считать среднее, но такой подход занимает слишком много памяти для больших $n$. К счастью, нам и не нужно точное среднее, а лишь оценку, поэтому воспользуемся экспоненциальным скользящим средним.
>
> $$v_t = \gamma \cdot v_{t-1} + (1-\gamma) x$$
>
> Чтобы накопить что-нибудь, будем умножать уже накопленное значение на коэффициент сохранения $0 < \gamma < 1$ и прибавлять очередную величину, умноженную на $1-\gamma$. Чем ближе $\gamma$ к единице, тем больше окно накопления и сильнее сглаживание — история $x$ начинает влиять сильнее, чем каждое очередное $x$. Если $x = 0$ c какого-то момента, $v_t$ затухают по геометрической прогрессии, экспоненциально, отсюда и название. Применим экспоненциальное бегущее среднее, чтобы накапливать градиент целевой функции нашей сети:
>
> $$v_t = \gamma \cdot v_{t-1} + \eta \nabla_w J( w)$$
> 
>$$w_{t+1} = w_{t} - v_t$$
>
> [Другой источник, другие обозначения:](http://ruder.io/optimizing-gradient-descent/)
> $$m_t =  \gamma \cdot m_{t-1} + \eta \cdot g_t\\
> w_{t+1} = w_t - m_t \\
> w_{t + 1} = w_t - (\gamma \cdot m_{t-1} + \eta \cdot g_t)$$

Он сочетает в себе и идею накопления движения и идею более слабого обновления весов для типичных признаков.

От Нестерова $Adam$ отличается тем, что мы накапливаем не $\Delta w$, а значения градиента.

Кроме того, мы хотим знать, как часто градиент изменяется. Авторы алгоритма предложили для этого оценивать ещё и среднюю нецентрированную дисперсию:

$$v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2,$$

где $g_t = \nabla_w J( w_t ),\ \ \ J( w )$ - целевая функция.

Легко заметить, что это уже знакомый нам $E[g^2]_t$, то есть это бегущее среднее в момент $t$:
$$E[g^2]_t = \gamma E[g^2]_{t-1} + (1 - \gamma) g^2_t,$$
так что по сути тут нет отличий от $RMSProp$.

Обновление моментума будет по формуле:
$$m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t$$

Важное отличие состоит в начальной калибровке $m_t$ и $v_t$: они страдают от той же проблемы, что и $E[g^2]_t$ в $RMSProp$:
если задать нулевое начальное значение, то они будут долго накапливаться, особенно при большом окне накопления $(0 \ll \beta_1 < 1,\ 0 \ll \beta_2 < 1)$,
а какие-то изначальные значения — это ещё два гиперпараметра.

Никто не хочет ещё два гиперпараметра, так что мы искусственно увеличиваем $m_t$ и $v_t$ на первых шагах:
* для $m_t$ примерно на $0 < t < 10$
* для $v_t$ примерно на $0 < t < 1000$

$$\hat{m}_t = \frac{m_t}{1 - \beta^t_1}, \;\\
\hat{v}_t = \frac{v_t}{1 - \beta^t_2}$$

В итоге, правило обновления весов получается следующим:
$$w_{t+1} = w_{t} - \dfrac{\eta}{\sqrt{\hat{v}_t + \varepsilon}} \hat{m}_t$$

Авторы Adam предлагают в качестве значений по умолчанию: $$\beta_1 = 0.9, \beta_2 = 0.999, \varepsilon = 10^{-8}$$ и утверждают, что алгоритм выступает лучше или примерно так же, как и все предыдущие алгоритмы на широком наборе датасетов за счёт начальной калибровки.

#### Nadam

$Nadam -\ Nesterov\ -\ accelerated\ ADAptive\ Moment\ estimation$
[Источник того, что ниже - лекции.](https://docs.google.com/document/d/1HXz9Q7sp50WDAd3Fuk0eqzikXN90KmClK8fkG-2y0Iw/edit#heading=h.pfqx4aqepwsx)

Раз уж мы в предыдущем методе воспользовались импульсом, то можно и про Нестерова тоже вспомнить. Итого, заменяем в предыдущем Adam-e переход по сумме векторов импульса и  градиента на последовательный переход: сначала по вектору импульса, потом по вектору градиента в новой точке.


Формулы для $Nadam:$

Сначала правило обновления весов по $Adam:$

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_10/adam.png?raw=true">
</p>

Теперь правило обновления весов по $Nadam:$

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_10/nadam.png?raw=true">
</p>

[Источник картинок/](http://cs229.stanford.edu/proj2015/054_report.pdf)
[Источник, где можно почитать формулки, но... лучше не читать.](http://ruder.io/optimizing-gradient-descent/)

## Вопрос 2: Object detection. IoU, mAP. R-CNN. Fast R-CNN.

[Истоник того, что ниже - лекции.](https://docs.google.com/document/d/1nRC4KPQAxBrNBLu8Jr7Ii_xa5ztsmN6ZupraCeYUIVQ/edit)

>Мы остановились на том, что ошибка в соревновании ImageNet была уменьшена до $3\%$, что меньше ошибки разметки данных. После этого ImageNet стал челленджем по выделению объектов на картинке. Но вообще-то такой челлендж уже есть: Pascal VOC Challenge. Этот challenge состоит из двух частей: object detection, где надо сделать выделение объекта рамочкой и классифицировать объект (например, сказать, что в боксе самолет), и segmentation, где надо про каждый пиксель сказать: это какой-то объект, какой-то другой объект или фон.
>
> Но сейчас все всё равно идут в ImageNet, потому что там больше база. А люди, которые делали Pascal VOC, начинали его делать в 2007 и перестали в 2012 из-за отсутствия значимых улучшений. Но в 2012 начался deep learning. И все начали делать сетки и проверять их на Pascal. Например, обозначение 7++12 в статье значит, что обучались на датасетах этого соревнования за все годы.
> 
### Метрики: IoU

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_10/iou.png?raw=true">
</p>

_TRUE - if $IoU > 0.5$_

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_10/iou1.png?raw=true">
</p>

### Метрики: mPA

[Источник того, что ниже - стэковерфлов.](https://stackoverflow.com/questions/36274638/map-metric-in-object-detection-and-computer-vision)

Commonly, $IoU > 0.5$ means that it was a hit, otherwise it was a fail. For each class, one can calculate the

* $True\ Positive\ TP(c)$: a proposal was made for class $c$ and there actually was an object of class $c$
    * $False\ Positive\ FP(c)$: a proposal was made for class $c$, but there is no object of class $c$
* $Average\ Precision$ for class $c:$
$$AP(c) = \frac{\#TP(c)}{\#TP(c) + \#FP(c)}$$
* $Mean Average Precision$ for class $c:$
$$mAP(c) = \frac{1}{|classes|} \cdot \sum_{c \in classes} \frac{\#TP(c)}{\#TP(c) + \#FP(c)}$$

### R-CNN

[Источник того, что ниже - хабр.](https://habr.com/post/421299/)

Архитектура сети R-CNN (Regions With CNNs) была разработана командой из UC Berkley для применения Convolution Neural Networks к задаче object detection. Существовавшие на тот момент подходы к решению таких задач приблизились к масимуму своих возможностей и значимо улучшить их показатели не получалось. 

CNN хорошо показывали себя в классификации изображений, и в данной сети они по сути были применены для того же самого. Для этого на вход CNN подавалось не всё изображение целиком, а предварительно выделенные другим способом регионы, на которых предположительно имеются какие-то объекты. На тот момент таких подходов было несколько, авторы выбрали Selective Search, хотя они указывают, что особых причин для предпочтения именно его нет.

В качестве CNN-сети использовалась так же готовая архитектура — CaffeNet (AlexNet). Такие нейросети, как и другие для набора изображений ImageNet, проводят классификацию на 1000 классов. R-CNN разрабатывалась для детектирования объектов меньшего количества классов ($N = 20$ или $200$), поэтому последний классификационный слой CaffeNet был заменён на слой с N+1 выходами (с дополнительным классом для фона).

Selective Search выдавал около $2000$ регионов разного размера и соотношений сторон, однако CaffeNet принимает на вход изображения фиксированного размера $227х227$ пикселей, поэтому перед подачей регионов на вход сети их приходилось модифицировать. Для этого изображение из региона заключалось в наименьший охватывающий квадрат. Вдоль той (меньшей) стороны, по которой образовывались поля, добавлялось несколько «контекстных» (окружающих регион) пикселей изображения, оставшаяся часть поля ничем не заполнялась. Полученный квадрат масштабировался под размер $227x227$ и подавался на вход CaffeNet.

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_10/caffe_resize.png?raw=true">
</p>

Несмотря на то, что CNN тренировалась на распознавание $N + 1$ классов, в итоге она использовалась только для извлечения фиксированного $4096$-размерного вектора признаков. Непосредственным определением объекта на изображении занимались $N$ линейных SVM, каждый из которых проводил бинарную классификацию по своему типу объектов, определяя есть ли такой в переданном регионе или нет. В оригинальном документе вся процедура иллюстрируется такой схемой:

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_10/r_cnn.png?raw=true">
</p>

Авторы утверждают, что процесс классификации в SVM происходит весьма производительно, представляя собой по сути просто матричные операции. Полученные из CNN векторы признаков объединяются по всем регионам в матрицу $2000 * 4096$, которая затем умножается на матрицу $4096 * N$ с весами SVM.

Надо отметить, что полученные при помощи Selective Search регионы только могут содержать какие-то объекты, и не факт, что содержат их целиком. Считать ли регион содержащим объект или нет, определялось по метрике Intersection over Union (IoU). 

IoU так же использовался для отсеивания избыточного количества регионов, содержащих определённый объект (non-maximum suppression). Если IoU некоторого региона с регионом, получившим для того же объекта максимальный результат, был выше некоторого порога, первый регион просто отбрасывался.

> **Bounding Box Regression**
> В ходе процедуры error analysis авторы так же разработали метод, позволяющий уменьшить ошибку выделения охватывающей рамки объекта — bounding-box regression. После классификации содержимого региона-кандидата, при помощи линейной регрессии на основе признаков из CNN определялись четыре параметра — $(dx, dy, dw, dh)$. Они описывали, насколько надо сдвинуть центр рамки региона по х и у, а также на сколько изменить её ширину и высоту, чтобы точнее охватывать распознанный объект.

Таким образом, процедуру детектирования объектов сетью R-CNN можно разделить на следующие шаги:

1. Выделение регионов-кандидатов при помощи Selective Search.
2. Преобразование региона в размер, принимаемый CNN CaffeNet.
3. Получение при помощи CNN $4096$-размерного вектора признаков.
4. Проведение $N$ бинарных классификаций каждого вектора признаков при помощи N линейных SVM.
5. Линейная регрессия параметров рамки региона для более точного охвата объекта

### Fast R-CNN

Несмотря на высокие результаты, производительность R-CNN была всё же невысока, особенно для более глубоких, чем CaffeNet сетей (таких как VGG16). Кроме того, обучение bounding box regressor и SVM требовало сохранения на диск большого количества признаков, поэтому оно было дорогим с точки зрения размера хранилища.

Авторы Fast R-CNN предложили ускорить процесс за счёт пары модификаций:

* Пропускать через CNN не каждый из $2000$ регионов-кандидатов по отдельности, а всё изображение целиком. Предложенные регионы потом накладываются на полученную общую карту признаков;
* Вместо независимого обучения трёх моделей (CNN, SVM, bbox regressor) совместить все процедуры тренировки в одну.

Преобразование признаков, попавших в разные регионы, к фиксированному размеру производилось при помощи процедуры _RoIPooling_. Окно региона шириной w и высотой h делилось на сетку, имеющую $H×W$ ячеек размером $h/H × w/W$. (Авторы документа использовали $W = H = 7$). По каждой такой ячейке проводился Max Pooling для выбора только одного значения, давая таким образом результирующую матрицу признаков H×W.

Бинарные SVM не использовались, вместо этого выбранные признаки передавались на полносвязанный слой, а затем на два параллельных слоя: softmax с $K+1 $выходами (по одному на каждый класс $+ 1$ для фона) и bounding box regressor. 

Общая архитектура сети выглядит так:

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_10/fast_r_cnn.png?raw=true">
</p>

Для совместного обучения softmax-классификатора и bbox regressor-а использовалась объединённая loss-функция:

$$L(p, u, t^u, v) = L_{cls}(p, u) + \lambda\cdot[u \ge 1]\cdot L_{loc}(t^u, v),$$
где
$u$ — класс объекта, реально изображённого в регионе-кандидате;
$L_{cls} = -\log{p_u}$ – log loss для класса u;
$v = (v_x, v_y, v_w, v_h)$ – реальные изменения рамки региона для более точного охватывания объекта;
$t^u = (t_x^y, t_y^u, t_w^u, t_h^u)$ – предсказанные изменения рамки региона;
$L_{loc}$ – loss-функция между предсказанными и реальными изменениями рамки;
$[u \ge 1]$ – индикаторная функция, равная 1, когда , и 0, когда наоборот. Классом обозначается фон (т.е. отсутствие объектов в регионе).
$\lambda$ – коэффициент, предназначенный для балансирования вклада обоих loss-функций в общий результат. Во всех экспериментах авторов документа, он, однако, был равен 1.