# Билет №9
## Вопрос 1: Optimizers: Stochastic Gradient Descent, Momentum, Nesterov Momentum.
> ### Chain rule
> $Chain\ rule$ -- производная сложной функции.
> 
> **Цепное правило (правило дифференцирования сложной функции)** позволяет вычислить производную композиции двух и более функций на основе индивидуальных производных. Если функция $f$ имеет производную в точке $x_{0}$, а функция $g$ имеет производную в точке $y_{0}=f(x_{0})$, то сложная функция $h(x)=g(f(x))$ также имеет производную в точке $x_{0}$.
> 
> В обозначениях Лейбница цепное правило для вычисления производной функции $y=y(x)$, где $x=x(t)$, принимает следующий вид:
> 
> $$\frac{dy}{dt} = \frac{dy}{dx} \cdot \frac{dt}{dt}$$
> ### Backpropagation
> $Backpropagation$ -- метод обновления весов сеток.
> [Источник того, что ниже -- википедия.](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B8)
> 
> **Метод обратного распространения ошибки** — метод вычисления градиента, который используется при обновлении весов многослойного перцептрона.
> Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы.
> #### Описание работы
> Алгоритм обратного распространения ошибки применяется для многослойного перцептрона. У сети есть множество входов $x_{1},...,x_{n}$, множество выходов $Outputs$ и множество внутренних узлов. Перенумеруем все узлы (включая входы и выходы) числами от $1$ до $N$ (сквозная нумерация, вне зависимости от топологии слоёв). Обозначим через  $w_{i,j}$ вес, стоящий на ребре, соединяющем $i$-й и $j$-й узлы, а через $o_i$ — выход $i$-го узла. Если нам известен обучающий пример (правильные ответы сети $t_k$, $k \in \mathrm{Outputs}$), то функция ошибки, полученная по методу наименьших квадратов, выглядит так:
>
>$$E(\{w_{i,j}\}) = \tfrac{1}{2} \!\! \sum_{k \in \mathrm{Outputs}} \!\!\! (t_k - o_k)^2 $$
>
> Как модифицировать веса? Мы будем реализовывать стохастический градиентный спуск, то есть будем подправлять веса после каждого обучающего примера и, таким образом, «двигаться» в многомерном пространстве весов. Чтобы «добраться» до минимума ошибки, нам нужно «двигаться» в сторону, противоположную градиенту, то есть, на основании каждой группы правильных ответов, добавлять к каждому весу $w_{i,j}$
>
> $$\Delta w_{i,j} = -\eta \frac {\partial E}{\partial w_{i,j}},$$
>
> где $0 < \eta < 1$ — множитель, задающий скорость «движения»
>
>Производная считается следующим образом. Пусть сначала $j \in \mathrm{Outputs}$, то есть интересующий нас вес входит в нейрон последнего уровня. Сначала отметим, что $w_{i,j}$ влияет на выход сети только как часть суммы  $S_j = \sum_{i} w_{i,j}x_{i}$, где сумма берётся по входам $j$-го узла. Поэтому
>
> $$\cfrac{\partial E}{\partial w_{i,j}} = \cfrac{\partial E}{\partial S_j}\, \cfrac{\partial S_j}{\partial w_{i,j}} = x_{i} \cfrac{\partial E}{\partial S_j} $$
>
> Аналогично, $S_j$ влияет на общую ошибку только в рамках выхода $j$-го узла $o_j$ (напоминаем, что это выход всей сети). Поэтому
>
>$$\cfrac{\partial E}{\partial S_j} = \cfrac{\partial E}{\partial o_j}\,\cfrac{\partial o_j}{\partial S_j} = \\ =\left (\cfrac{\partial}{\partial o_j}\,\cfrac{1}{2}\sum_{k \in \mathrm{Outputs}}(t_k - o_k)^2 \right ) \!\! \left (\cfrac{\partial \operatorname{f}(S)}{\partial S}\mid_{S=S_j} \right) = \\
\\ = \left ( \cfrac{1}{2}\, \cfrac{\partial}{\partial o_j}(t_j - o_j)^2 \right) (o_j(1 - o_j)) 2\alpha = - 2 \alpha o_j(1 - o_j)(t_j - o_j),$$
>
>где $f(S)$ — соответствующая сигмоида, в данном случае — экспоненциальная
>
>Если же $j$-й узел — не на последнем уровне, то у него есть выходы; обозначим их через $Children(j)$. В этом случае
>
>$$\cfrac{\partial E}{\partial S_j} = \sum_{k \in \mathrm{Children}(j)} \cfrac{\partial E}{\partial S_k}\, \cfrac{\partial S_k}{\partial S_j},$$
>и
>
>$$\cfrac{\partial S_k}{\partial S_j} = \cfrac{\partial S_k}{\partial o_j}\, \cfrac{\partial o_j}{\partial S_j} = w_{j,k} \cfrac{\partial o_j}{\partial S_j} = 2\alpha w_{j,k}o_j(1 - o_j).$$
>
>Но $\cfrac{\partial E}{\partial S_k}$ — это в точности аналогичная поправка, но вычисленная для узла следующего уровня. Будем обозначать её через $\delta _k$ — от $\Delta _k$ она отличается отсутствием множителя $(-\eta x_{i,j})$. Поскольку мы научились вычислять поправку для узлов последнего уровня и выражать поправку для узла более низкого уровня через поправки более высокого, можно уже писать алгоритм. Именно из-за этой особенности вычисления поправок алгоритм называется алгоритмом обратного распространения ошибки ($backpropagation$).
>
>Краткое резюме проделанной работы:
>* для узла последнего уровня:
>$$\delta _j = -2\alpha o_j(1 - o_j)(t_j - o_j)$$
>* для внутреннего узла сети:
>$$\delta _j = 2\alpha o_j(1 - o_j) \!\! \sum_{k \in \mathrm{Children}(j)} \!\! \delta _k w_{j,k}$$
>* для всех узлов:
>$$\Delta w_{i,j} = -\eta \delta _j o_{i},$$
>где $o_{i}$ это тот же $x_{i}$ в формуле для $\cfrac{\partial E}>{\partial w_{i,j}}$.
>
>[Источник того, что ниже - лекции.](https://docs.google.com/document/d/1HXz9Q7sp50WDAd3Fuk0eqzikXN90KmClK8fkG-2y0Iw/edit#)
>
>Итак, мы посчитали градиенты по каждому весу, но это градиенты функции ошибки, ее мы хотим минимизировать, так что веса будем двигать в сторону, противоположную градиенту. Замечание: могут встречаться оба варианта: подвигать по градиенту (если мы максимизируем какой-нибудь “gain”) или против (если минимизируем loss).
>Сам алгоритм:
>* инициализировать веса $w_{i, j}$ случайными величинами
>* $forward\ step$ - получаем $o_j$
>* $backward\ step$ - получаем $\delta_j$
>* обновляем веса
>
>Этот алгоритм лучше запускать несколько раз с разными начальными весами, потому что начиная с разных точек в пространстве весов и значения функции потерь мы можем скатываться в разные минимумы.

### Оптимизаторы

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/GD.png?raw=true">
</p>

#### Стохастический градиентный спуск
градиент каждый раз считается для какого-то одного input-а, поэтому для всего датасета у нас получается много разных градиентов.  Первое, что можно сделать -- взять среднее, если все градиенты более-менее в одном направлении (это простой градиентный спуск). Есть стохастический градиентный спуск: считаем не по всем точкам, а по какому-то подмножеству ($batch$). Сдвигаем веса, берем следующий batch и так далее. Этот вариант зачастую работает лучше первого.

Есть такое понятие как эпоха ($epoch$): мы берем бэтчи и когда прошли все примеры в датасете, то закончили эпоху. 
То есть для простого градиентного спуска один шаг -- одна эпоха. 
Для $SGD$ -- $$|epoch| = \frac{|dataset|}{|batch|}.$$
Эпох обычно много (запускаются они друг за другом, обучая и обучая модель), потому что после одной эпохи мы недообучимся. Бэтчи обычно меняются между эпохами, то есть конкретный пример может попасть в другой бэтч на следующей эпохе. Это нужно, например, для того, чтобы лучше работать с выбросами. Если к “хорошим” примерам в бэтч попал выброс, то он будет “тянуть” градиент в свою сторону. Если не перемешать бэтчи, то это влияние будет постоянным.

##### Достоинства SGD
* Метод приспособлен для динамического (online) обучения, когда обучающие объекты поступают потоком, и надо быстро обновлять вектор w.
* Алгоритм способен обучаться на избыточно больших выборках за счёт того, что случайной подвыборки может хватить для обучения.
* Возможны различные стратегии обучения. Если выборка избыточно большая, или обучение происходит динамически, то допустимо не сохранять обучающие объекты. Если выборка маленькая, то можно повторно предъявлять для обучения одни и те же объекты.

##### Недостатки SGD
* Алгоритм может не сходиться или сходиться слишком медленно
* Как правило, функционал $Q$ многоэкстремален и процесс градиентного спуска может "застрять" в одном из локальных минимумов. Для борьбы с этим используют технику встряхивания коэффициентов ($jog of weights$). Она заключается в том, чтобы при каждой стабилизации функционала производить случайные модификации вектора w в довольно большой окрестности текущего значения и запускать процесс градиентного спуска из новых точек.
* При большой размерности пространства признаков $n$ и/или малой длине выборки $l$ возможно переобучение;
* Если функция активации имеет горизонтальные асимптоты, то процесс может попасть в состояние "паралича".

### Momentum

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/sgd1.png?raw=true">
</p>

Итак, пусть был какой-то шаг, мы куда-то попали, хотим приехать в глобальный минимум, а градиент говорит ехать в локальный. Выходят из такой ситуации с помощью импульса. Импульс запоминает, куда мы ехали.

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/sgd_momentum.png?raw=true">
</p>

Иногда импульса будет хватать, чтобы перескочить. Тут появляется скорость v. Импульс -- коэффициент от предыдущей скорости (в deep learning). Скорость определяется предыдущим импульсом, коэффициентом при импульсе и градиентом. Мы начинаем со скорости ноль. Первым шагом мы начинаем куда-то ехать и запоминаем направление и скорость, с которой ехали.

> Почему $momentum$ работает:
> 1. Мы ищем производную не по всем данным, а только по небольшой его части, батчу, поэтому получаемые производные приближенные или, можно сказать, что шумные. Значит, мы не всегда можем идти в правильном направлении. Поэтому, взвешенные переходы дают нам лучшее приближение к правильному направлению.
> 2. Вблизи локальных экстремумов часто бывает, что появляются $ravine$, овраги, т.е. плоскость наклоняется в одной координате больше, чем в остальных. Поэтому $SGD$ будет осциллировать по этим резко наклоняющимся координатом, вместо тотго, чтобы идти в правильном направлении. Изображено на картинке ниже:
> <p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/sgd_momentum2.png?raw=true">
</p>

### Nesterov Momentum

При обычном импульсе вектор итогового направления получается как сумма вектора градиента, посчитанного в точке $x_0$ и вектора импульса, тоже посчитанного в точке $x_0$:
$$\vec{step}|_{x_0} =  \vec{m}|_{x_0} + \vec{grad}|_{x_0}$$

В случае импульса Нестерова результирующий вектор мы считаем по-другому, а именно
$$\vec{step}|_{x_0} = \vec{m}|_{x_0} + \vec{grad}|_{x_1},$$
где $x_1$ -- конец вектора импульса.

На картинке ниже

* **красная** - градиент
* **голубая** - импульс
* **зеленая** - как бы мы пошли при обычном использовании импульса
* **оранжевая** - итоговое направление по импульсу Нестерова
<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/nesterov_momentum.png?raw=true">
</p>

Иногда этот способ срабатывает хуже, иногда лучше. Это просто еще один вариант, который надо знать и пробовать.


## Вопрос 2: Object detection. Faster R-CNN, Mask R-CNN.

[Истоник того, что ниже - хабр.](https://habr.com/post/421299/)

После улучшений, сделанных в Fast R-CNN, самым узким местом нейросети оказался механизм генерации регионов-кандидатов. В 2015 команда из Microsoft Research смогла сделать этот этап значительно более быстрым. Они предложили вычислять регионы не по изначальному изображению, а опять же по карте признаков, полученных из CNN. Для этого был добавлен модуль под названием Region Proposal Network (RPN). Новая архитектура целиком выглядит следующим образом:


<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/faster_r_cnn.png?raw=true">
</p>

В рамках RPN по извлечённым CNN признакам скользят «мини-нейросетью» с небольшим $3х3$ окном. Полученные с её помощью значения передаются в два параллельных полносвязанных слоя: box-regression layer (reg) и box-classification layer (cls). Выходы этих слоёв базируются на так называемых anchor-ах: $k$ рамках для каждого положения скользящего окна, имеющих разные размеры и соотношения сторон. Reg-слой для каждого такого anchor-а выдаёт по $4$ координаты, корректирующие положение охватывающей рамки; cls-слой выдаёт по два числа – вероятности того, что рамка содержит хоть какой-то объект или что не содержит. В документе это иллюстрируется такой схемой:

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/faster_r_cnn1.png?raw=true">
</p>

Процесс обучения reg и cls слоёв объединённый; loss-функцию они имеют общую, представляющую собой сумму loss-функций каждого из них, с балансирующим коэффициентом.

Оба слоя RPN выдают только предложения для регионов-кандидатов. Те из них, которые имеют высокую вероятность содержания какого-либо объекта, передаются дальше в модуль детектирования объектов и уточнения охватывающей рамки, который по-прежнему реализован как Fast R-CNN.

Для того, чтобы разделять признаки, получаемые в CNN, между RPN и модулем детектирования, процесс обучения всей сети построен итерационно, с использованием нескольких шагов:
1. Инициализируется и обучается на определение регионов-кандидатов RPN-часть. 
2. С использованием предлагаемых RPN регионов заново обучается Fast R-CNN часть. 
3. Обученная сеть детектирования используется, чтобы инициализировать веса для RPN. Общие convolution-слои, однако, фиксируются и производится донастройка только слоёв, специфичных для RPN. 
4. С зафиксированными convolution-слоями окончательно донастраивается Fast R-CNN.

Предложенная схема не является единственной, и даже в текущем виде она может быть продолжена дальнейшими итерационными шагами, но авторы оригинального исследования проводили эксперименты именно после такого обучения.

### Mask R-CNN

Mask R-CNN развивает архитектуру Faster R-CNN путём добавления ещё одной ветки, которая предсказывает положение маски, покрывающей найденный объект, и, таким образом решает уже задачу instance segmentation. Маска представляет собой просто прямоугольную матрицу, в которой на некоторой позиции
* $1$ означает принадлежность соответствующего пикселя объекту заданного класса
* $0$ означает, что пиксель объекту не принадлежит.

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/mask_r_cnn.png?raw=true">
</p>

Визуализация разноцветных масок на исходных изображениях может давать красочные картинки:

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/mask_r_cnn1.png?raw=true">
</p>

Авторы документа условно разделяют разработанную архитектуру на CNN-сеть вычисления признаков изображения, называемую ими backbone, и head — объединение частей, отвечающих за предсказание охватывающей рамки, классификацию объекта и определение его маски. Loss функция для них общая и включает три компонента:
$$L = L_{cls} + L_{box} + L_{mask}$$    

Выделение маски происходит в class-agnostic стиле: маски предсказываются отдельно для каждого класса, без предварительного знания, что изображено в регионе, и потом просто выбирается маска класса, победившего в независимом классификаторе. Утверждается, что такой подход более эффективен, чем опирающийся на априорное знание класса.

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/mask_r_cnn_results.png?raw=true">
</p>

Помимо выскоких результатов в задачах instance segmentation и object detection, Mask R-CNN оказалась пригодной для определения поз людей на фотографии (human pose estimation). Ключевой момент здесь — выделение опорных точек (keypoints), таких как левое плечо, правый локоть, правое колено и т.п., по которым можно нарисовать каркас позиции человека:

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/mask_r_cnn_humans.png?raw=true">
</p>