# Билет №9
## Вопрос 1: Optimizers: Stochastic Gradient Descent, Momentum, Nesterov Momentum.

### Chain rule
$Chain\ rule$ -- производная сложной функции.

**Цепное правило (правило дифференцирования сложной функции)** позволяет вычислить производную композиции двух и более функций на основе индивидуальных производных. Если функция $f$ имеет производную в точке $x_{0}$, а функция $g$ имеет производную в точке $y_{0}=f(x_{0})$, то сложная функция $h(x)=g(f(x))$ также имеет производную в точке $x_{0}$.

В обозначениях Лейбница цепное правило для вычисления производной функции $y=y(x)$, где $x=x(t)$, принимает следующий вид:

$$\frac{dy}{dt} = \frac{dy}{dx} \cdot \frac{dt}{dt}$$


### Backpropagation
$Backpropagation$ -- метод обновления весов сеток.

[Источник того, что ниже -- википедия.](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B8)

**Метод обратного распространения ошибки** — метод вычисления градиента, который используется при обновлении весов многослойного перцептрона.

Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы.

#### Описание работы

Алгоритм обратного распространения ошибки применяется для многослойного перцептрона. У сети есть множество входов $x_{1},...,x_{n}$, множество выходов $Outputs$ и множество внутренних узлов. Перенумеруем все узлы (включая входы и выходы) числами от $1$ до $N$ (сквозная нумерация, вне зависимости от топологии слоёв). Обозначим через  $w_{i,j}$ вес, стоящий на ребре, соединяющем $i$-й и $j$-й узлы, а через $o_i$ — выход $i$-го узла. Если нам известен обучающий пример (правильные ответы сети $t_k$, $k \in \mathrm{Outputs}$), то функция ошибки, полученная по методу наименьших квадратов, выглядит так:

$$E(\{w_{i,j}\}) = \tfrac{1}{2} \!\! \sum_{k \in \mathrm{Outputs}} \!\!\! (t_k - o_k)^2 $$

ак модифицировать веса? Мы будем реализовывать стохастический градиентный спуск, то есть будем подправлять веса после каждого обучающего примера и, таким образом, «двигаться» в многомерном пространстве весов. Чтобы «добраться» до минимума ошибки, нам нужно «двигаться» в сторону, противоположную градиенту, то есть, на основании каждой группы правильных ответов, добавлять к каждому весу $w_{i,j}$

$$\Delta w_{i,j} = -\eta \frac {\partial E}{\partial w_{i,j}},$$

где $0 < \eta < 1$ — множитель, задающий скорость «движения»


Производная считается следующим образом. Пусть сначала $j \in \mathrm{Outputs}$, то есть интересующий нас вес входит в нейрон последнего уровня. Сначала отметим, что $w_{i,j}$ влияет на выход сети только как часть суммы  $S_j = \sum_{i} w_{i,j}x_{i}$, где сумма берётся по входам $j$-го узла. Поэтому

$$\cfrac{\partial E}{\partial w_{i,j}} = \cfrac{\partial E}{\partial S_j}\, \cfrac{\partial S_j}{\partial w_{i,j}} = x_{i} \cfrac{\partial E}{\partial S_j} $$

Аналогично, $S_j$ влияет на общую ошибку только в рамках выхода $j$-го узла $o_j$ (напоминаем, что это выход всей сети). Поэтому

$$\cfrac{\partial E}{\partial S_j} = \cfrac{\partial E}{\partial o_j}\,\cfrac{\partial o_j}{\partial S_j} = \\ =\left (\cfrac{\partial}{\partial o_j}\,\cfrac{1}{2}\sum_{k \in \mathrm{Outputs}}(t_k - o_k)^2 \right ) \!\! \left (\cfrac{\partial \operatorname{f}(S)}{\partial S}\mid_{S=S_j} \right) = \\
\\ = \left ( \cfrac{1}{2}\, \cfrac{\partial}{\partial o_j}(t_j - o_j)^2 \right) (o_j(1 - o_j)) 2\alpha = - 2 \alpha o_j(1 - o_j)(t_j - o_j),$$

где $f(S)$ — соответствующая сигмоида, в данном случае — экспоненциальная


Если же $j$-й узел — не на последнем уровне, то у него есть выходы; обозначим их через $Children(j)$. В этом случае

$$\cfrac{\partial E}{\partial S_j} = \sum_{k \in \mathrm{Children}(j)} \cfrac{\partial E}{\partial S_k}\, \cfrac{\partial S_k}{\partial S_j},$$

и

$$\cfrac{\partial S_k}{\partial S_j} = \cfrac{\partial S_k}{\partial o_j}\, \cfrac{\partial o_j}{\partial S_j} = w_{j,k} \cfrac{\partial o_j}{\partial S_j} = 2\alpha w_{j,k}o_j(1 - o_j).$$

Но $\cfrac{\partial E}{\partial S_k}$ — это в точности аналогичная поправка, но вычисленная для узла следующего уровня. Будем обозначать её через $\delta _k$ — от $\Delta _k$ она отличается отсутствием множителя $(-\eta x_{i,j})$. Поскольку мы научились вычислять поправку для узлов последнего уровня и выражать поправку для узла более низкого уровня через поправки более высокого, можно уже писать алгоритм. Именно из-за этой особенности вычисления поправок алгоритм называется алгоритмом обратного распространения ошибки ($backpropagation$).

Краткое резюме проделанной работы:
* для узла последнего уровня:
$$\delta _j = -2\alpha o_j(1 - o_j)(t_j - o_j)$$
* для внутреннего узла сети:
$$\delta _j = 2\alpha o_j(1 - o_j) \!\! \sum_{k \in \mathrm{Children}(j)} \!\! \delta _k w_{j,k}$$
* для всех узлов:
$$\Delta w_{i,j} = -\eta \delta _j o_{i},$$
где $o_{i}$ это тот же $x_{i}$ в формуле для $\cfrac{\partial E}{\partial w_{i,j}}$.

[Источник того, что ниже - лекции.](https://docs.google.com/document/d/1HXz9Q7sp50WDAd3Fuk0eqzikXN90KmClK8fkG-2y0Iw/edit#)

Итак, мы посчитали градиенты по каждому весу, но это градиенты функции ошибки, ее мы хотим минимизировать, так что веса будем двигать в сторону, противоположную градиенту. Замечание: могут встречаться оба варианта: подвигать по градиенту (если мы максимизируем какой-нибудь “gain”) или против (если минимизируем loss).
Сам алгоритм:
* инициализировать веса $w_{i, j}$ случайными величинами
* $forward\ step$ - получаем $o_j$
* $backward\ step$ - получаем $\delta_j$
* обновляем веса

Этот алгоритм лучше запускать несколько раз с разными начальными весами, потому что начиная с разных точек в пространстве весов и значения функции потерь мы можем скатываться в разные минимумы.


### Оптимизаторы

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/GD.png?raw=true">
</p>

#### Стохастический градиентный спуск
градиент каждый раз считается для какого-то одного input-а, поэтому для всего датасета у нас получается много разных градиентов.  Первое, что можно сделать -- взять среднее, если все градиенты более-менее в одном направлении (это простой градиентный спуск). Есть стохастический градиентный спуск: считаем не по всем точкам, а по какому-то подмножеству ($batch$). Сдвигаем веса, берем следующий batch и так далее. Этот вариант зачастую работает лучше первого.

Есть такое понятие как эпоха ($epoch$): мы берем бэтчи и когда прошли все примеры в датасете, то закончили эпоху. 
То есть для простого градиентного спуска один шаг -- одна эпоха. 
Для $SGD$ -- $$|epoch| = \frac{|dataset|}{|batch|}.$$
Эпох обычно много (запускаются они друг за другом, обучая и обучая модель), потому что после одной эпохи мы недообучимся. Бэтчи обычно меняются между эпохами, то есть конкретный пример может попасть в другой бэтч на следующей эпохе. Это нужно, например, для того, чтобы лучше работать с выбросами. Если к “хорошим” примерам в бэтч попал выброс, то он будет “тянуть” градиент в свою сторону. Если не перемешать бэтчи, то это влияние будет постоянным.

##### Достоинства SGD
* Метод приспособлен для динамического (online) обучения, когда обучающие объекты поступают потоком, и надо быстро обновлять вектор w.
* Алгоритм способен обучаться на избыточно больших выборках за счёт того, что случайной подвыборки может хватить для обучения.
* Возможны различные стратегии обучения. Если выборка избыточно большая, или обучение происходит динамически, то допустимо не сохранять обучающие объекты. Если выборка маленькая, то можно повторно предъявлять для обучения одни и те же объекты.

##### Недостатки SGD
* Алгоритм может не сходиться или сходиться слишком медленно
* Как правило, функционал $Q$ многоэкстремален и процесс градиентного спуска может "застрять" в одном из локальных минимумов. Для борьбы с этим используют технику встряхивания коэффициентов ($jog of weights$). Она заключается в том, чтобы при каждой стабилизации функционала производить случайные модификации вектора w в довольно большой окрестности текущего значения и запускать процесс градиентного спуска из новых точек.
* При большой размерности пространства признаков $n$ и/или малой длине выборки $l$ возможно переобучение;
* Если функция активации имеет горизонтальные асимптоты, то процесс может попасть в состояние "паралича".

### Momentum

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/sgd1.png?raw=true">
</p>

Итак, пусть был какой-то шаг, мы куда-то попали, хотим приехать в глобальный минимум, а градиент говорит ехать в локальный. Выходят из такой ситуации с помощью импульса. Импульс запоминает, куда мы ехали.

<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/sgd_momentum.png?raw=true">
</p>

Иногда импульса будет хватать, чтобы перескочить. Тут появляется скорость v. Импульс -- коэффициент от предыдущей скорости (в deep learning). Скорость определяется предыдущим импульсом, коэффициентом при импульсе и градиентом. Мы начинаем со скорости ноль. Первым шагом мы начинаем куда-то ехать и запоминаем направление и скорость, с которой ехали.

> Почему $momentum$ работает:
> 1. Мы ищем производную не по всем данным, а только по небольшой его части, батчу, поэтому получаемые производные приближенные или, можно сказать, что шумные. Значит, мы не всегда можем идти в правильном направлении. Поэтому, взвешенные переходы дают нам лучшее приближение к правильному направлению.
> 2. Вблизи локальных экстремумов часто бывает, что появляются $ravine$, овраги, т.е. плоскость наклоняется в одной координате больше, чем в остальных. Поэтому $SGD$ будет осциллировать по этим резко наклоняющимся координатом, вместо тотго, чтобы идти в правильном направлении. Изображено на картинке ниже:
> <p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/sgd_momentum2.png?raw=true">
</p>

### Nesterov Momentum

При обычном импульсе вектор итогового направления получается как сумма вектора градиента, посчитанного в точке $x_0$ и вектора импульса, тоже посчитанного в точке $x_0$:
$$\vec{step}|_{x_0} =  \vec{m}|_{x_0} + \vec{grad}|_{x_0}$$

В случае импульса Нестерова результирующий вектор мы считаем по-другому, а именно
$$\vec{step}|_{x_0} = \vec{m}|_{x_0} + \vec{grad}|_{x_1},$$
где $x_1$ -- конец вектора импульса.

На картинке ниже

* **красная** - градиент
* **голубая** - импульс
* **зеленая** - как бы мы пошли при обычном использовании импульса
* **оранжевая** - итоговое направление по импульсу Нестерова
<p align="center">
  <img src = "https://github.com/natalymr/dl-notes/blob/master/pictures/question_9/nesterov_momentum.png?raw=true">
</p>

Иногда этот способ срабатывает хуже, иногда лучше. Это просто еще один вариант, который надо знать и пробовать.


## Вопрос 2: Object detection. Faster R-CNN, Mask R-CNN.